{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f47f0b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-02T16:41:21.722030Z",
     "iopub.status.busy": "2023-07-02T16:41:21.721667Z",
     "iopub.status.idle": "2023-07-02T16:41:21.733945Z",
     "shell.execute_reply": "2023-07-02T16:41:21.732898Z"
    },
    "papermill": {
     "duration": 0.022335,
     "end_time": "2023-07-02T16:41:21.736331",
     "exception": false,
     "start_time": "2023-07-02T16:41:21.713996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a289a",
   "metadata": {
    "papermill": {
     "duration": 0.002905,
     "end_time": "2023-07-02T16:41:21.742761",
     "exception": false,
     "start_time": "2023-07-02T16:41:21.739856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4edba20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T16:41:21.751435Z",
     "iopub.status.busy": "2023-07-02T16:41:21.750539Z",
     "iopub.status.idle": "2023-07-02T16:41:31.164197Z",
     "shell.execute_reply": "2023-07-02T16:41:31.163115Z"
    },
    "papermill": {
     "duration": 9.421056,
     "end_time": "2023-07-02T16:41:31.166872",
     "exception": false,
     "start_time": "2023-07-02T16:41:21.745816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf40ce",
   "metadata": {
    "papermill": {
     "duration": 0.002924,
     "end_time": "2023-07-02T16:41:31.173225",
     "exception": false,
     "start_time": "2023-07-02T16:41:31.170301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# storing dateset Images and Labels in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d8ceaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T16:41:31.181559Z",
     "iopub.status.busy": "2023-07-02T16:41:31.180805Z",
     "iopub.status.idle": "2023-07-02T16:42:41.324629Z",
     "shell.execute_reply": "2023-07-02T16:42:41.323455Z"
    },
    "papermill": {
     "duration": 70.151049,
     "end_time": "2023-07-02T16:42:41.327409",
     "exception": false,
     "start_time": "2023-07-02T16:41:31.176360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_dir = '/kaggle/input/5-flower-types-classification-dataset/flower_images'#string containing the path of our main directory\n",
    "image_size = 224\n",
    "batch = 64\n",
    "x = []\n",
    "y = []\n",
    "class_names = sorted(os.listdir(dataset_dir)) #gives the sorted list of sub directories in the directory\n",
    "for class_name in class_names :\n",
    "    class_dir = os.path.join(dataset_dir,class_name) #gives path of each sub-directory in the dataset_dir directory\n",
    "    images = os.listdir(class_dir) #gives a list of contents of the sub directories i.e the list of images in this case\n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(class_dir,image_name) #gives path of the image\n",
    "        image = cv2.imread(image_path) #gives us the image from path in matrix form\n",
    "        image = cv2.resize(image,(image_size, image_size)) #ensures constant size of all the images\n",
    "        image  = image / 255.0 #rescaling images to reduce number of parameters to make it easier for the model to train\n",
    "        x.append(image) # storing the images in the list x\n",
    "        y.append(class_name) #storing the class_name of the corresponding imagein list x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9877956",
   "metadata": {
    "papermill": {
     "duration": 0.003,
     "end_time": "2023-07-02T16:42:41.334187",
     "exception": false,
     "start_time": "2023-07-02T16:42:41.331187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing and One Hot Encoding (to avoid ordinality in classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f48d61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T16:42:41.342539Z",
     "iopub.status.busy": "2023-07-02T16:42:41.342133Z",
     "iopub.status.idle": "2023-07-02T16:42:46.339903Z",
     "shell.execute_reply": "2023-07-02T16:42:46.338584Z"
    },
    "papermill": {
     "duration": 5.005333,
     "end_time": "2023-07-02T16:42:46.342722",
     "exception": false,
     "start_time": "2023-07-02T16:42:41.337389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lilly' 'Lotus' 'Orchid' 'Sunflower' 'Tulip']\n",
      "x_train shape: (4000, 224, 224, 3)\n",
      "x_test shape: (1000, 224, 224, 3)\n",
      "y_train shape: (4000, 5)\n",
      "y_test shape: (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder #for transforming classes of object type to intiger\n",
    "from tensorflow.keras.utils import to_categorical #for performing one hot encoding on class labels\n",
    "\n",
    "label_encoding = LabelEncoder()\n",
    "y_encoded = label_encoding.fit_transform(y) #forming a list containing labels in intiger forrmat\n",
    "\n",
    "x = np.array(x)\n",
    "y_encoded = np.array(y_encoded)\n",
    "\n",
    "print(label_encoding.classes_)\n",
    "num_classes = len(label_encoding.classes_)\n",
    "\n",
    "y_encoded = to_categorical(y_encoded, num_classes = num_classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x , y_encoded, test_size = 0.2, random_state = 42) #splaiitng training and resting data\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab73196",
   "metadata": {
    "papermill": {
     "duration": 0.003446,
     "end_time": "2023-07-02T16:42:46.351989",
     "exception": false,
     "start_time": "2023-07-02T16:42:46.348543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c9f312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T16:42:46.360921Z",
     "iopub.status.busy": "2023-07-02T16:42:46.360025Z",
     "iopub.status.idle": "2023-07-02T16:42:46.624742Z",
     "shell.execute_reply": "2023-07-02T16:42:46.623486Z"
    },
    "papermill": {
     "duration": 0.278619,
     "end_time": "2023-07-02T16:42:46.634018",
     "exception": false,
     "start_time": "2023-07-02T16:42:46.355399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 74, 74, 100)       57700     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 100)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 100)       90100     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 100)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 32005     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181,597\n",
      "Trainable params: 181,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'same', activation = 'relu', input_shape = (224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "model.add(Conv2D(filters = 100, kernel_size = (3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3,3)))\n",
    "model.add(Conv2D(filters = 100, kernel_size = (3,3), padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb46a87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T16:42:46.646261Z",
     "iopub.status.busy": "2023-07-02T16:42:46.645624Z",
     "iopub.status.idle": "2023-07-02T17:02:00.879316Z",
     "shell.execute_reply": "2023-07-02T17:02:00.878156Z"
    },
    "papermill": {
     "duration": 1154.242829,
     "end_time": "2023-07-02T17:02:00.881933",
     "exception": false,
     "start_time": "2023-07-02T16:42:46.639104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "400/400 [==============================] - 234s 581ms/step - loss: 1.2517 - accuracy: 0.4780 - val_loss: 1.0565 - val_accuracy: 0.5650\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 230s 576ms/step - loss: 0.9901 - accuracy: 0.6127 - val_loss: 1.0007 - val_accuracy: 0.6040\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 228s 570ms/step - loss: 0.8201 - accuracy: 0.6945 - val_loss: 0.8063 - val_accuracy: 0.6920\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 228s 571ms/step - loss: 0.6100 - accuracy: 0.7740 - val_loss: 0.6428 - val_accuracy: 0.7710\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 230s 575ms/step - loss: 0.4368 - accuracy: 0.8430 - val_loss: 0.6804 - val_accuracy: 0.7780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7949a43bb610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "model.fit(x_train, y_train, batch_size = 10, epochs = 5, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e97963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-02T17:02:01.144437Z",
     "iopub.status.busy": "2023-07-02T17:02:01.143626Z",
     "iopub.status.idle": "2023-07-02T17:02:17.586596Z",
     "shell.execute_reply": "2023-07-02T17:02:17.585641Z"
    },
    "papermill": {
     "duration": 16.576396,
     "end_time": "2023-07-02T17:02:17.588638",
     "exception": false,
     "start_time": "2023-07-02T17:02:01.012242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 16s 497ms/step - loss: 0.6804 - accuracy: 0.7780\n",
      "0.6803770065307617\n",
      "0.777999997138977\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test)\n",
    "print(test_loss)\n",
    "print(test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1270.287622,
   "end_time": "2023-07-02T17:02:21.732165",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-02T16:41:11.444543",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
