{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-05T15:56:29.579209Z","iopub.execute_input":"2023-07-05T15:56:29.579458Z","iopub.status.idle":"2023-07-05T15:56:29.614389Z","shell.execute_reply.started":"2023-07-05T15:56:29.579437Z","shell.execute_reply":"2023-07-05T15:56:29.613649Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Importing necessary Libraries","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nimport cv2\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T15:56:43.610916Z","iopub.execute_input":"2023-07-05T15:56:43.611577Z","iopub.status.idle":"2023-07-05T15:56:43.616348Z","shell.execute_reply.started":"2023-07-05T15:56:43.611548Z","shell.execute_reply":"2023-07-05T15:56:43.615416Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# storing dateset Images and Labels in lists","metadata":{}},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/5-flower-types-classification-dataset/flower_images'#string containing the path of our main directory\nimage_size = 224\nbatch = 64\nx = []\ny = []\nclass_names = sorted(os.listdir(dataset_dir)) #gives the sorted list of sub directories in the directory\nfor class_name in class_names :\n    class_dir = os.path.join(dataset_dir,class_name) #gives path of each sub-directory in the dataset_dir directory\n    images = os.listdir(class_dir) #gives a list of contents of the sub directories i.e the list of images in this case\n    for image_name in images:\n        image_path = os.path.join(class_dir,image_name) #gives path of the image\n        image = cv2.imread(image_path) #gives us the image from path in matrix form\n        image = cv2.resize(image,(image_size, image_size)) #ensures constant size of all the images\n        image  = image / 255.0 #rescaling images to reduce number of parameters to make it easier for the model to train\n        x.append(image) # storing the images in the list x\n        y.append(class_name) #storing the class_name of the corresponding imagein list x","metadata":{"execution":{"iopub.status.busy":"2023-07-05T15:56:46.360667Z","iopub.execute_input":"2023-07-05T15:56:46.361015Z","iopub.status.idle":"2023-07-05T15:57:46.397031Z","shell.execute_reply.started":"2023-07-05T15:56:46.360993Z","shell.execute_reply":"2023-07-05T15:57:46.396140Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing and One Hot Encoding (to avoid ordinality in classes)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder #for transforming classes of object type to intiger\nfrom tensorflow.keras.utils import to_categorical #for performing one hot encoding on class labels\n\nlabel_encoding = LabelEncoder()\ny_encoded = label_encoding.fit_transform(y) #forming a list containing labels in intiger forrmat\n\nx = np.array(x)\ny_encoded = np.array(y_encoded)\n\nprint(label_encoding.classes_)\nnum_classes = len(label_encoding.classes_)\n\ny_encoded = to_categorical(y_encoded, num_classes = num_classes)\n\nx_train, x_test, y_train, y_test = train_test_split(x , y_encoded, test_size = 0.2, random_state = 42) #splaiitng training and resting data\n\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\nprint('y_train shape:', y_train.shape)\nprint('y_test shape:', y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-05T15:57:53.389035Z","iopub.execute_input":"2023-07-05T15:57:53.389405Z","iopub.status.idle":"2023-07-05T15:57:55.607264Z","shell.execute_reply.started":"2023-07-05T15:57:53.389377Z","shell.execute_reply":"2023-07-05T15:57:55.606144Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['Lilly' 'Lotus' 'Orchid' 'Sunflower' 'Tulip']\nx_train shape: (4000, 224, 224, 3)\nx_test shape: (1000, 224, 224, 3)\ny_train shape: (4000, 5)\ny_test shape: (1000, 5)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training the NN","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu', input_shape = (224, 224, 3)))\nmodel.add(MaxPooling2D(pool_size = (3, 3)))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (3,3)))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'same', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (3,3)))\nmodel.add(Flatten())\nmodel.add(Dense(num_classes, activation = 'softmax'))\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-05T15:58:02.844873Z","iopub.execute_input":"2023-07-05T15:58:02.845195Z","iopub.status.idle":"2023-07-05T15:58:03.068466Z","shell.execute_reply.started":"2023-07-05T15:58:02.845174Z","shell.execute_reply":"2023-07-05T15:58:03.067560Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 224, 224, 128)     3584      \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 74, 74, 128)      0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 74, 74, 128)       147584    \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 24, 24, 128)      0         \n 2D)                                                             \n                                                                 \n conv2d_2 (Conv2D)           (None, 24, 24, 128)       147584    \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 8, 8, 128)        0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 8192)              0         \n                                                                 \n dense (Dense)               (None, 5)                 40965     \n                                                                 \n=================================================================\nTotal params: 339,717\nTrainable params: 339,717\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy')\nmodel.fit(x_train, y_train, batch_size = 10, epochs = 10, validation_data = (x_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-05T15:58:07.178908Z","iopub.execute_input":"2023-07-05T15:58:07.179231Z","iopub.status.idle":"2023-07-05T16:51:31.615562Z","shell.execute_reply.started":"2023-07-05T15:58:07.179208Z","shell.execute_reply":"2023-07-05T16:51:31.614009Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1/10\n400/400 [==============================] - 320s 797ms/step - loss: 1.2679 - accuracy: 0.4703 - val_loss: 1.0872 - val_accuracy: 0.5840\nEpoch 2/10\n400/400 [==============================] - 315s 787ms/step - loss: 1.0070 - accuracy: 0.6080 - val_loss: 0.9615 - val_accuracy: 0.6290\nEpoch 3/10\n400/400 [==============================] - 322s 804ms/step - loss: 0.8250 - accuracy: 0.6883 - val_loss: 0.8706 - val_accuracy: 0.6910\nEpoch 4/10\n400/400 [==============================] - 317s 794ms/step - loss: 0.6716 - accuracy: 0.7430 - val_loss: 0.7765 - val_accuracy: 0.7240\nEpoch 5/10\n400/400 [==============================] - 317s 793ms/step - loss: 0.5174 - accuracy: 0.8145 - val_loss: 0.7773 - val_accuracy: 0.7360\nEpoch 6/10\n400/400 [==============================] - 317s 793ms/step - loss: 0.4027 - accuracy: 0.8520 - val_loss: 0.8002 - val_accuracy: 0.7570\nEpoch 7/10\n400/400 [==============================] - 316s 790ms/step - loss: 0.2776 - accuracy: 0.9003 - val_loss: 0.7554 - val_accuracy: 0.8020\nEpoch 8/10\n400/400 [==============================] - 318s 794ms/step - loss: 0.2191 - accuracy: 0.9265 - val_loss: 0.7976 - val_accuracy: 0.8010\nEpoch 9/10\n400/400 [==============================] - 317s 792ms/step - loss: 0.1747 - accuracy: 0.9417 - val_loss: 0.9121 - val_accuracy: 0.8240\nEpoch 10/10\n400/400 [==============================] - 318s 796ms/step - loss: 0.1135 - accuracy: 0.9617 - val_loss: 0.8304 - val_accuracy: 0.8410\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ff74842b610>"},"metadata":{}}]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(x_test,y_test)\nprint(test_loss)\nprint(test_accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-07-05T16:51:55.704547Z","iopub.execute_input":"2023-07-05T16:51:55.704808Z","iopub.status.idle":"2023-07-05T16:52:17.543157Z","shell.execute_reply.started":"2023-07-05T16:51:55.704785Z","shell.execute_reply":"2023-07-05T16:52:17.541750Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 20s 633ms/step - loss: 0.8304 - accuracy: 0.8410\n0.8304072618484497\n0.8410000205039978\n","output_type":"stream"}]}]}